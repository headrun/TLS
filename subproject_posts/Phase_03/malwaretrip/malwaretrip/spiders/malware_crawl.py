import scrapy
import MySQLdb
from scrapy import Selector
from scrapy.http import Request
#from urlparse import urlparse
from urlparse import urljoin
from scrapy.xlib.pydispatch import dispatcher
from scrapy import signals
import re
import sys

sys.path.append('/home/epictions/tls_scripts/tls_utils')
import tls_utils as utils
query = utils.generate_upsert_query_posts_crawl('malwaretrip')

class MalwareCrawl(scrapy.Spider):
    name= "malware_crawl"
    start_urls=['https://malwaretips.com/']

    def __init__(self):
	self.conn = MySQLdb.connect(db='posts',host='127.0.0.1',user='tls_dev',passwd='hdrn!', use_unicode = True, charset = 'utf8')
        self.cursor = self.conn.cursor()
        dispatcher.connect(self.close_conn, signals.spider_closed)

    def close_conn(self, spider):
        self.conn.commit()
        self.conn.close()

    def parse(self,response):
        sel=Selector(response)
        url="https://malwaretips.com"
        urls =sel.xpath('//div[@class="uix_categoryStrip-content"]/a/@href').extract()
        for urlm in urls:
            urlm = "https://malwaretips.com" #+ urlm
            yield Request(urlm,callback = self.parse1)

    def parse1(self,response):
        sel=Selector(response)
        url="https://malwaretips.com"
        sur =  sel.xpath('//h3[@class="node-title"]/a/@href').extract()
        #import pdb; pdb.set_trace()
        for surl in sur:
            surl = "https://malwaretips.com" + surl
            yield Request(surl,callback = self.parse2)

    def parse2(self,response):
        sel=Selector(response)
        url="https://malwaretips.com"
        yur=  sel.xpath('//div[@class="structItem-title"]/a[@data-tp-primary="on"]/@href').extract()
        for yurl in yur:
            if 'http' not in yurl:
                yurl = urljoin("https://malwaretips.com",yurl)
                #import pdb; pdb.set_trace()
                sk = yurl.split('.')[-1]
            values =  {'sk':sk,'post_url':yurl,'crawl_status':0,'reference_url':response.url}
            self.cursor.execute(query,values)
            self.conn.commit()
        next_page= urljoin("https://malwaretips.com",''.join(set(sel.xpath('//a[@class = "pageNav-jump pageNav-jump--next"]/@href').extract())))
        #import pdb; pdb.set_trace()
        if next_page:
            yield Request(next_page,callback=self.parse2)

