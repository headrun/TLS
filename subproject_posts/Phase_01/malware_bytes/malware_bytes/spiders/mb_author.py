import scrapy
from scrapy.spider import Spider
from scrapy.selector import Selector
from scrapy.http import Request
import datetime
import time
import MySQLdb
import json
import mb_xpaths
from scrapy import signals
from scrapy.xlib.pydispatch import dispatcher
import sys
sys.path.append('/home/epictions/tls_scripts/tls_utils')
import tls_utils as utils
from elasticsearch import Elasticsearch
import hashlib
que = utils.generate_upsert_query_authors('malwarebytes')

class formus(scrapy.Spider):
   name="malwarebytes_author"
   start_urls=["https://forums.malwarebytes.com"]

   def __init__(self):
       self.es = Elasticsearch(['10.2.0.90:9342'])
       self.conn, self.cursor = self.mysql_conn() 
       select_query = 'select DISTINCT(links) from mb_authors_crawl'
       self.cursor.execute(select_query)
       self.conn.commit()
       self.data = self.cursor.fetchall()
       dispatcher.connect(self.close_conn, signals.spider_closed)

   def mysql_conn(self):
       conn = MySQLdb.connect(db="posts",host="localhost",user="root",passwd="qwe123",use_unicode=True,charset="utf8")
       cursor = conn.cursor()
       return conn,cursor


   def close_conn(self, spider):
       self.conn.commit()
       self.conn.close()

   def parse(self,response):
       for url in self.data:
	   url = url[0]
           meta_query = 'select DISTINCT(auth_meta) from mb_authors_crawl where links = "%s"'%url.encode('utf8')
           self.cursor.execute(meta_query)
	   self.conn.commit()
           meta_query = self.cursor.fetchall()
           activetime=[]
           Threadtitle = []
           for da1 in meta_query:
               meta = json.loads(da1[0])
               activetime.append(meta.get('time',''))
               Threadtitle.append(meta.get('Threadtitle','').encode('utf8'))
           PublishTime = set(activetime)
           Threadtitle = ', '.join(set(Threadtitle))
           meta = {'PublishTime':PublishTime,'Threadtitle': Threadtitle}
           if url and meta:
               yield Request(url, callback=self.parse_author,meta = meta)

   def parse_author(self, response):
       sel = Selector(response)
       username = ''.join(sel.xpath(mb_xpaths.usernames).extract()).strip().encode('ascii','ignore')
       if username:
	   up_que = 'update mb_authors_crawl set crawl_status = 1 where links="%s"'%(response.url)
	   self.cursor.execute(up_que)
	   self.conn.commit()
       else:
	   up_que = 'update mb_authors_crawl set crawl_status = 9 where links="%s"'%(response.url)
           self.cursor.execute(up_que)
           self.conn.commit()
       activetime_ = response.meta.get("PublishTime")
       Threadtitle = response.meta.get('Threadtitle','-')
       activetime = []
       CONTENT_COUNT = ''.join(sel.xpath(mb_xpaths.contentcount).extract()).replace('\t','').replace('\n','').encode('ascii','ignore')
       for activetime_i in activetime_:
           try:
               dt = time.gmtime(int(activetime_i)/1000)
               activetime_i = """[{ "year": "%d","month": "%d", "dayofweek": "%d", "hour": "%d", "count": "%s" }]"""%\
                      (dt.tm_year,dt.tm_mon,dt.tm_wday,dt.tm_hour,CONTENT_COUNT)
               activetime.append(activetime_i)
           except:
               activetime.append('-')
       totalposts =''.join( CONTENT_COUNT)
       join_time = ''.join(sel.xpath(mb_xpaths.jointime).extract()).replace(' ','').encode('ascii','ignore')
       try:
           join_time_ = datetime.datetime.strptime(join_time, '%m/%d/%Y%I:%M%p')
           join_date = time.mktime(join_time_.timetuple())*1000
       except:
           try:
               join_time_ = datetime.datetime.strptime(join_time, '%d/%m/%Y%I:%M%p')
               join_date = time.mktime(join_time_.timetuple())*1000
           except:
               pass

       last = ''.join(sel.xpath(mb_xpaths.lasts).extract()).encode('ascii','ignore')
       try:
           publishdate = datetime.datetime.strptime(last, '%m/%d/%Y %I:%M %p')
           lastactive = time.mktime(publishdate.timetuple())*1000
       except:
           lastactive = 0
       reputations = ''.join(sel.xpath('//div[@class="ipsDataItem_generic ipsType_break"]//span/@class').extract()).count('ipsPip')
       rank=''.join(''.join(sel.xpath(mb_xpaths.ranks).extract())).strip().encode('utf8')
       
       FetchTime = int(datetime.datetime.now().strftime("%s")) * 1000
       try:
           total_posts = int(totalposts.replace(',',''))
       except:
           total_posts = 0
       json_val = {}
       json_val.update({
           'username':MySQLdb.escape_string(username),
           'domain':"forums.malwarebytes.com",
           'auth_sign':"", 
           'join_date':join_date, 
           'lastactive':lastactive,
           'totalposts': total_posts, 
           'fetch_time':FetchTime, 
           'groups':"", 
           'reputation':reputations, 
           'credits':"",
           'awards': "",
           'rank':rank,
           'activetimes': str(', '.join(activetime)) ,
           'contact_info': ''
           })
       self.es.index(index="forum_author", doc_type='post', id=hashlib.md5(username).hexdigest(), body=json_val)
